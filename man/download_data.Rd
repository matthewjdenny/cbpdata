% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/download_data.R
\name{download_data}
\alias{download_data}
\title{Download Bills Data}
\usage{
download_data(bill_list, existing_data = NULL, chunk_size = 1000,
  intermediate_directory = NULL, sleep_time = 1,
  status_interval = 100, start_chunk = 1, recombine_data = TRUE)
}
\arguments{
\item{bill_list}{A list object generated by the `get_bill_list()` function.}

\item{existing_data}{An optional data frame with existing bills data. The
`URL` and `last_updated` fields in these data will be used to filter which
observations are new/have changed, and only new data will be downloaded if
this is the case.}

\item{chunk_size}{Defaults to 1000. If `intermediate_directory` is not NULL,
then documents will be saved in chunks of 1000 to the intermediate directory,
then read back in to R when the process is complete. This allows for the user
to save results along the way to mitigate the effects of crashes.}

\item{intermediate_directory}{Defaults to NULL. If not NULL, then the data
will be downloaded and saved in chunks of `chunk_size` to this directory.
Make sure that a trailing "/" is used on this directory so that it can be
joined to the intermediate file names, which will be of the form:
"Data_Chunk_i.Rdata" where "i" is the chunk number.}

\item{sleep_time}{The number of seconds to sleep in between downloading new
data from the govinfo.gov website. Defaults to 1.}

\item{status_interval}{Defaults to 100. The interval (number of bills) at
which progress should be reported.}

\item{start_chunk}{If `intermediate_directory` is not NULL (so chunking is
being used), then this determines which chunk to start with. This can be
helpful for splitting scraping up across multiple machines. Defaults to 1.}

\item{recombine_data}{Logical, defaults to TRUE. If TRUE, and
`intermediate_directory` is provided, then at the end of scraping, all
datasets will be read in and recombined. If FALSE, then no further action
will be taken and NULL will be returned by the function:}
}
\value{
A data.frame containing the raw xml/html returned by the web scraper,
along with relevant metadata.
}
\description{
Downloads the bill metadata and text.
}
